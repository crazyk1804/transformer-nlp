{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b style=\"color: #5b7daf\">01.Transformer</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### <b style=\"color: #f86461\">RNN</b>\n",
    "> ![RNN](./resources/RNN.png)\n",
    "> - 언어 모델에 유용함  \n",
    "> - 각 RNN 셀이 상태를 가짐  \n",
    "> - 상태와 데이터 2개의 입력  \n",
    "> - 하나의 상태로 데이터가 압축되어 손실발생  \n",
    "> - 어텐션을 사용해서 극복  \n",
    "> - 순차적 입력이라는 한계.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### <b style=\"color: #f86461\">일반적 모델학습</b>\n",
    "> - 사전학습 -> 전이학습/파인튜닝 -> 도메인 적용  \n",
    "> - 아키텍쳐 구현 -> 사전학습 로드 -> 데이터 전처리 -> 데이터로더 구현 -> loss, optimizer 정의\n",
    "> - 표준화 된 소스가 아니어서 새로운 도메인에 적용 어려움  \n",
    "> - 그래서 **허깅페이스**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure from your\n",
    "online store in Germany. Unfortunately, when I opened the package, I discovered to\n",
    "my horror that I had been sent an action figure of Megatron instead! As  a lifelong\n",
    "enemy of the Decepticons, I hope you can understand my dilemma. To resolve the\n",
    "issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered.\n",
    "Enclosed are copies of my records concerning this purchase. I expect to hear from\n",
    "you soon. Sincerely, Bumblebee.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 분류\n",
    "from transformers import pipeline\n",
    "classifier = pipeline('text-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.901546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.901546"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.990263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.999312\n",
       "1  POSITIVE  0.990263"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_size = len(text) // 2\n",
    "head, tail = text[:half_size], text[half_size:]\n",
    "outputs = classifier([head, tail])\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.879010</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>Germany</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.556567</td>\n",
       "      <td>Mega</td>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.590256</td>\n",
       "      <td>##tron</td>\n",
       "      <td>212</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.669691</td>\n",
       "      <td>Decept</td>\n",
       "      <td>254</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.498349</td>\n",
       "      <td>##icons</td>\n",
       "      <td>260</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.775361</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>351</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.987854</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>368</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.812097</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>503</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.879010         Amazon      5   11\n",
       "1         MISC  0.990859  Optimus Prime     36   49\n",
       "2          LOC  0.999755        Germany     90   97\n",
       "3         MISC  0.556567           Mega    208  212\n",
       "4          PER  0.590256         ##tron    212  216\n",
       "5          ORG  0.669691         Decept    254  260\n",
       "6         MISC  0.498349        ##icons    260  265\n",
       "7         MISC  0.775361       Megatron    351  359\n",
       "8         MISC  0.987854  Optimus Prime    368  381\n",
       "9          PER  0.812097      Bumblebee    503  512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개체명 인식(NER: Named Entity Recognition)\n",
    "ner_tagger = pipeline('ner', aggregation_strategy='simple')\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  entity_group     score           word  start  end\n",
      "0          ORG  0.927624         Amazon      5   11\n",
      "1         MISC  0.983534  Optimus Prime     36   49\n",
      "2          LOC  0.999749        Germany     90   97\n",
      "3          PER  0.813427       Megatron    208  216\n",
      "4          ORG  0.569146             De    254  256\n",
      "  entity_group     score           word  start  end\n",
      "0         MISC  0.508540          ##ico      4    7\n",
      "1         MISC  0.511747           Mega     95   99\n",
      "2          PER  0.590190         ##tron     99  103\n",
      "3         MISC  0.961195  Optimus Prime    112  125\n",
      "4          PER  0.780502      Bumblebee    247  256\n"
     ]
    }
   ],
   "source": [
    "multi_outputs = ner_tagger([head, tail])\n",
    "for output in multi_outputs:\n",
    "    print(pd.DataFrame(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631292</td>\n",
       "      <td>336</td>\n",
       "      <td>359</td>\n",
       "      <td>an exchange of Megatron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                   answer\n",
       "0  0.631292    336  359  an exchange of Megatron"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문-답변(Question-Answering)\n",
    "reader = pipeline('question-answering')\n",
    "question = 'What does the customer want?'\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your min_length=56 must be inferior than your max_length=45.\n",
      "/Users/crazyk/opt/anaconda3/envs/tf-2307/lib/python3.8/site-packages/transformers/generation/utils.py:1380: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (45). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when he opened the package, he discovered to his horror that he had been sent an action figure of Megatron instead.'}]\n"
     ]
    }
   ],
   "source": [
    "# 요약 (Summarization)\n",
    "summarizer = pipeline('summarization')\n",
    "outputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when he opened the package, he discovered to his horror that he had been sent an action figure of Megatron instead.\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length=56 must be inferior than your max_length=20.\n",
      "/Users/crazyk/opt/anaconda3/envs/tf-2307/lib/python3.8/site-packages/transformers/generation/utils.py:1380: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (20). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bumblebee ordered an Optimus Prime action figure from an online store in Germany. When\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(text, max_length=20, clean_up_tokenization_spaces=True)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Obtaining dependency information for sacremoses from https://files.pythonhosted.org/packages/0b/f0/89ee2bc9da434bd78464f288fdb346bc2932f2ee80a90b2a4bbbac262c74/sacremoses-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in /Users/crazyk/opt/anaconda3/envs/tf-2307/lib/python3.8/site-packages (from sacremoses) (2023.10.3)\n",
      "Requirement already satisfied: click in /Users/crazyk/opt/anaconda3/envs/tf-2307/lib/python3.8/site-packages (from sacremoses) (8.1.6)\n",
      "Requirement already satisfied: joblib in /Users/crazyk/opt/anaconda3/envs/tf-2307/lib/python3.8/site-packages (from sacremoses) (1.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/crazyk/opt/anaconda3/envs/tf-2307/lib/python3.8/site-packages (from sacremoses) (4.65.0)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sehr geehrter Amazon, letzte Woche habe ich eine Optimus Prime Action Figur aus Ihrem Online-Shop in Deutschland bestellt. Leider, als ich das Paket öffnete, entdeckte ich zu meinem Entsetzen, dass ich stattdessen eine Action Figur von Megatron geschickt worden war! Als lebenslanger Feind der Decepticons, Ich hoffe, Sie können mein Dilemma verstehen. Um das Problem zu lösen, Ich fordere einen Austausch von Megatron für die Optimus Prime Figur habe ich bestellt. Eingeschlossen sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich erwarte, von Ihnen bald zu hören. Aufrichtig, Bumblebee.\n"
     ]
    }
   ],
   "source": [
    "# 번역 (Translation)\n",
    "translator = pipeline('translation_en_to_de', model='Helsinki-NLP/opus-mt-en-de')\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_long_text(text, max_length=10):\n",
    "    words = text.split(' ')\n",
    "    for i, word in enumerate(words):\n",
    "        if i % max_length == 0:\n",
    "            print()\n",
    "        print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sehr geehrter Amazon, letzte Woche habe ich eine Optimus Prime \n",
      "Action Figur aus Ihrem Online-Shop in Deutschland bestellt. Leider, als \n",
      "ich das Paket öffnete, entdeckte ich zu meinem Entsetzen, dass \n",
      "ich stattdessen eine Action Figur von Megatron geschickt worden war! \n",
      "Als lebenslanger Feind der Decepticons, Ich hoffe, Sie können mein \n",
      "Dilemma verstehen. Um das Problem zu lösen, Ich fordere einen \n",
      "Austausch von Megatron für die Optimus Prime Figur habe ich \n",
      "bestellt. Eingeschlossen sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich \n",
      "erwarte, von Ihnen bald zu hören. Aufrichtig, Bumblebee. "
     ]
    }
   ],
   "source": [
    "print_long_text(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dear Amazon, last week I ordered an Optimus Prime action \n",
      "figure from your\n",
      "online store in Germany. Unfortunately, when I opened \n",
      "the package, I discovered to\n",
      "my horror that I had been \n",
      "sent an action figure of Megatron instead! As  a \n",
      "lifelong\n",
      "enemy of the Decepticons, I hope you can understand my \n",
      "dilemma. To resolve the\n",
      "issue, I demand an exchange of Megatron \n",
      "for the Optimus Prime figure I ordered.\n",
      "Enclosed are copies of \n",
      "my records concerning this purchase. I expect to hear from\n",
      "you \n",
      "soon. Sincerely, Bumblebee.\n",
      "=============\n",
      "Customer service response:\n",
      "Dear Bumblebee, I am sorry to \n",
      "hear that your order was mixed up. It is as \n",
      "if I was told that I could not get the \n",
      "product to my\n",
      "the shelves, or that it needed to be \n",
      "resold. You are correct. I was told that it would \n",
      "not be necessary to send\n",
      "me the product back for new \n",
      "purchase at that time. The order "
     ]
    }
   ],
   "source": [
    "# 텍스트 생성 (Text Generation)\n",
    "generator = pipeline('text-generation')\n",
    "response = 'Dear Bumblebee, I am sorry to hear that your order was mixed up.'\n",
    "prompt = text + '\\n=============\\nCustomer service response:\\n' + response\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print_long_text(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### <b style=\"color: #f86461\">허깅페이스 생태계</b>\n",
    "> - 허브\n",
    "> - 토크나이저\n",
    "> - 데이터셋\n",
    "> - 엑셀러레이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
